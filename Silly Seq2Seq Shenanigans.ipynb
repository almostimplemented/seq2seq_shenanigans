{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/almostimplemented/seq2seq_shenanigans/blob/main/Silly%20Seq2Seq%20Shenanigans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16ab818f",
      "metadata": {
        "id": "16ab818f"
      },
      "source": [
        "# Seq2Seq to learn a simple integer subsequence code\n",
        "\n",
        "This is a small experiment of training a sequence-to-sequence (\"seq2seq\") model to learn a prescribed mapping between two sequences of decimal digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ea8229f9",
      "metadata": {
        "id": "ea8229f9",
        "outputId": "21d614c8-af23-4bb3-e6de-b36fc5f4034c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9b4db8",
      "metadata": {
        "id": "6f9b4db8"
      },
      "source": [
        "Here we define the mapping.\n",
        "\n",
        "The input $X$ is constructed as follows:\n",
        "\n",
        "$$X = (idx, len, x_0, ..., x_N)$$\n",
        "\n",
        "The output is a substring of the input, indicated by $idx$ and $len$:\n",
        "\n",
        "$$Y = (x_{idx}, ..., x_{idx + len - 1}, 0, ... 0)$$\n",
        "\n",
        "The tail of the output is simply padded with zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "35c54de0",
      "metadata": {
        "id": "35c54de0",
        "outputId": "c035fbbe-096f-4b69-f6da-3becf32523ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  tensor([2, 3, 1, 8, 2, 5, 8, 6, 4, 5])\n",
            "y =  tensor([2, 5, 8, 0, 0, 0, 0, 0])\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def generate_example(l=10):\n",
        "    sub_start_idx = random.randint(0,5)\n",
        "    sub_len = random.randint(2, l - 2 - sub_start_idx)\n",
        "    x_head = [sub_start_idx, sub_len]\n",
        "    x_tail = [random.randint(1, 9) for _ in range(l - 2)]\n",
        "    y_head = [i for i in x_tail[sub_start_idx:sub_start_idx + sub_len]]# + ([0]*(l - sub_len))\n",
        "    y_tail = [0 for _ in range(l - 2 - len(y_head))]\n",
        "    x = x_head + x_tail\n",
        "    y = y_head + y_tail\n",
        "    return torch.as_tensor(x_head + x_tail), torch.as_tensor(y_head + y_tail)\n",
        "\n",
        "\n",
        "x, y = generate_example()\n",
        "print(\"x = \", x)\n",
        "print(\"y = \", y)\n",
        "print(torch.equal(y[:x[1]], x[2 + x[0] : 2 + x[0] + x[1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e5c3a91",
      "metadata": {
        "id": "8e5c3a91"
      },
      "source": [
        "Here we wrap our example generator in `torch`'s `IterableDataset`. The only requirement of this base class is implementing the `__iter__` method, which should return an iterator over the data. We additionally implement `__len__` since we pass a size in as a parameter anyway. This will be useful later when computing average metrics across the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "39b982f2",
      "metadata": {
        "id": "39b982f2"
      },
      "outputs": [],
      "source": [
        "class SyntheticDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (generate_example() for _ in range(self.n))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628b6304",
      "metadata": {
        "id": "628b6304"
      },
      "source": [
        "# The Model Architecture\n",
        "\n",
        "The seq2seq model we use has two components: an _encoder_ and a _decoder_. The encoder processes the initial sequence from left-to-right and learns a mapping into an abstract feature space. This enconding yields a feature vector of dimensionality `hidden_dim`. First, we treat each decimal character as a \"word\" and learn an embedding function that will represent each number as a feature vector with `emb_dim` components. This yields a sequence of embedding vectors. We process each one by one with [`torch.nn.GRU`](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html). We will not cover the internal mechanisms, but the important point is that we process the full input sequence, element by element, and return the final \"hidden state\" as the representation of the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "844a8457",
      "metadata": {
        "id": "844a8457"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) # \"vocabulary size\" -> \"word vector dimensionality\"\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        #src.shape = (src len, batch size)\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        #embedded.shape = (src len, batch size, emb dim)\n",
        "        outputs, final = self.rnn(embedded)\n",
        "        \n",
        "        return final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da78e3f9",
      "metadata": {
        "id": "da78e3f9"
      },
      "source": [
        "The second part of the seq2seq model is a _decoder_. This also uses a GRU, but this time we use every intermediate output state, not only the final state. Every word decoded is fed back into the GRU, along with the current state. For the initial state, we use the final state of the encoder, and for the initial word we just use a zero vector.\n",
        "\n",
        "Note: During training, we know how many steps we need to decode (--> the length of the target $Y$). If we needed to run inference and we did not have access to the target sequence length, we would need to greedily decode until we reach an \"end-of-sequence\" (\"EOS\") character. As it turns out, the way we define our sequence naturally makes $0$ the EOS character, but since it is a deterministic / easily computable function, we can always pass in the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "932da605",
      "metadata": {
        "id": "932da605"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout = dropout)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, final):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, final = self.rnn(embedded, final)\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5abbb7",
      "metadata": {
        "id": "1f5abbb7"
      },
      "source": [
        "Finally we put everything together into our `Seq2Seq` module. \n",
        "\n",
        "Note that we force the encoder and decoder to have equal dimensionality. If we wished to change this, we could insert a learnable layer (such as a linear transformation) to map from one feature space to the other. \n",
        "\n",
        "Another trick used is something called \"teacher forcing\". When we are in the decoding phase, we need the previous element of the output sequence to predict the next. We can either use our last prediction OR we can use the ground truth. The latter choice is called \"teacher forcing\". We flip a coin to decide which to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9b8309b7",
      "metadata": {
        "id": "9b8309b7"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hidden_dim == decoder.hidden_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "           \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        # final hidden state of the encoder -> initial hidden state of the decoder\n",
        "        final = self.encoder(src)\n",
        "        # just feed zeros as input to seed the decoder input\n",
        "        input = torch.zeros_like(trg[0,:])\n",
        "        for t in range(0, trg_len):\n",
        "            output, final = self.decoder(input, final)\n",
        "            outputs[t] = output\n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)            \n",
        "            # teacher forcing probability\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b38807e",
      "metadata": {
        "id": "0b38807e"
      },
      "source": [
        "# Preparing the learning program\n",
        "\n",
        "Here we do the following steps:\n",
        "\n",
        "1. Configure the dimensionalities of the various components of the model.\n",
        "2. Instantiate the encoder, decoder, and use these to constructing the Seq2Seq model.\n",
        "3. Randomly initialize the weights of our model (uniformly across small values)\n",
        "4. Create the [optimizer](https://pytorch.org/docs/stable/optim.html) (we use [`Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html))\n",
        "5. Define the loss criteria (we use [`CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)). One thing to notice about this loss is that the target is a single decimal digit (0 - 9), whereas the model output is a vector of weights across each possibly digit. You can think of the model output as an unnormalized probability distribution. This is identical to applying [`LogSoftmax`](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html) to the final output vector and using Negative-Log-Likelihood Loss ([`NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html))\n",
        "6. Finally, we create a [`DataLoader`](https://pytorch.org/docs/stable/data.html) for training and another for validation during our optimization routine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "10005199",
      "metadata": {
        "id": "10005199",
        "outputId": "1a3fc555-439f-4750-ffdd-dc650105ff51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,177,034 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE=32\n",
        "INPUT_DIM = 10\n",
        "OUTPUT_DIM = 10\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "N_LAYERS = 3\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "d_train = DataLoader(SyntheticDataset(4096), batch_size=BATCH_SIZE)\n",
        "d_valid = DataLoader(SyntheticDataset(8), batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b23826e3",
      "metadata": {
        "id": "b23826e3"
      },
      "source": [
        "Here we define two helper functions to iterate over a dataset. They are very similar and should probably be refactored to share more logic.\n",
        "\n",
        "In `train`, we call `model.train()` to prepare our model for gradient descent optimizations. Then we iterate over batches from the input. Each batch is fed into the model and we capture its output for each example in the batch. Then we compute the loss across all predicted elements. Finally we call `loss.backward()`, which propogates the gradient of the loss w.r.t. each parameter through the entire network. We apply gradient clipping to avoid exploding gradients, and then safely call `optimizer.step()` to update the parameters with gradient descent.\n",
        "\n",
        "The `evaluate` method is similar, except we do not use the loss signal to change the network. This is an important difference when data is scarce: we do not want to every \"learn\", or (worse) \"memorize\", the validation / test examples. If we fed the loss signal to the network, these validation / testing examples would no longer give us an idea of how well the model will generalize to unseen examples. \n",
        "\n",
        "We also print out our predicted sequence in evaluate by taking the highest predicted digit for each sequence element.\n",
        "\n",
        "Last, we define a helper function to measure how long it takes to process the dataset once (AKA \"one epoch\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "35cc2961",
      "metadata": {
        "id": "35cc2961"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):    \n",
        "    model.train()    \n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(d_train):\n",
        "        # always reset your gradients!\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # note: we did not customize our DataLoader\n",
        "        #       our model wants the input shape to be (sequence_len, batch_size),\n",
        "        #       but by default the DataLoader simply stacks the dataset examples,\n",
        "        #       which yields a shape (batch_size, sequence_len).\n",
        "        #   \n",
        "        #       so we simply transpose\n",
        "        src = batch[0].T\n",
        "        trg = batch[1].T\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        \n",
        "        # predict sequence\n",
        "        output = model(src, trg)\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        output = output.view(-1, output_dim)\n",
        "        trg = trg.reshape(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch[0].T\n",
        "            trg = batch[1].T\n",
        "        \n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "            output = model(src, trg, 0) # disable teacher forcing\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.view(-1, output_dim)\n",
        "            trg = trg.reshape(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            print(\"Input: \", src.reshape(-1))\n",
        "            print(\"Output: \", output.argmax(1))\n",
        "            print(\"Target: \", trg)\n",
        "            print(\"Loss: \", loss)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29dba66e",
      "metadata": {
        "id": "29dba66e"
      },
      "source": [
        "Finally, all we have to do is run the training function. We will run for 16 epochs.\n",
        "\n",
        "You can see that in the first epoch, the outputs are not very good. By epoch 3 and 4, we are getting much more accurate predictions, but errors still occur. Soon our validation errors nearly drop to zero -- this is because we are intentionally using a small validation set so we can print out each example -- but the training loss continues to drop. By the end, our network seems to nearly never make an error and has fully learned the sequence coding scheme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e6a996e0",
      "metadata": {
        "id": "e6a996e0",
        "outputId": "0c8bae88-abb4-4897-a55b-62c4d2b19174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  tensor([3, 2, 1, 8, 5, 6, 9, 1, 4, 5], device='cuda:0')\n",
            "Output:  tensor([5, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 9, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.7166, device='cuda:0')\n",
            "Input:  tensor([0, 3, 2, 4, 4, 3, 1, 7, 6, 4], device='cuda:0')\n",
            "Output:  tensor([4, 4, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 4, 4, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.7886, device='cuda:0')\n",
            "Input:  tensor([5, 2, 1, 9, 8, 1, 1, 7, 9, 2], device='cuda:0')\n",
            "Output:  tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 9, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.7166, device='cuda:0')\n",
            "Input:  tensor([1, 7, 7, 3, 4, 3, 3, 6, 6, 1], device='cuda:0')\n",
            "Output:  tensor([3, 3, 3, 3, 3, 3, 3, 0], device='cuda:0')\n",
            "Target:  tensor([3, 4, 3, 3, 6, 6, 1, 0], device='cuda:0')\n",
            "Loss:  tensor(1.8924, device='cuda:0')\n",
            "Input:  tensor([2, 5, 1, 3, 8, 1, 5, 2, 3, 5], device='cuda:0')\n",
            "Output:  tensor([5, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 1, 5, 2, 3, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.8111, device='cuda:0')\n",
            "Input:  tensor([2, 5, 6, 1, 3, 1, 2, 1, 5, 3], device='cuda:0')\n",
            "Output:  tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 1, 2, 1, 5, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.4228, device='cuda:0')\n",
            "Input:  tensor([2, 6, 8, 5, 4, 5, 8, 6, 8, 1], device='cuda:0')\n",
            "Output:  tensor([8, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 5, 8, 6, 8, 1, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(2.1906, device='cuda:0')\n",
            "Input:  tensor([0, 6, 5, 7, 7, 1, 5, 8, 2, 3], device='cuda:0')\n",
            "Output:  tensor([1, 5, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 7, 7, 1, 5, 8, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.5359, device='cuda:0')\n",
            "Epoch: 01 | Time: 0m 5s\n",
            "\tTrain Loss: 1.331 | Train PPL:   3.783\n",
            "\t Val. Loss: 1.384 |  Val. PPL:   3.992\n",
            "Input:  tensor([5, 2, 7, 7, 6, 5, 6, 6, 2, 1], device='cuda:0')\n",
            "Output:  tensor([6, 6, 6, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.6342, device='cuda:0')\n",
            "Input:  tensor([5, 3, 5, 4, 9, 9, 6, 4, 8, 3], device='cuda:0')\n",
            "Output:  tensor([9, 9, 3, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 8, 3, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.7566, device='cuda:0')\n",
            "Input:  tensor([1, 4, 1, 1, 5, 4, 6, 4, 1, 6], device='cuda:0')\n",
            "Output:  tensor([1, 1, 4, 4, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 5, 4, 6, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.7990, device='cuda:0')\n",
            "Input:  tensor([5, 3, 3, 1, 6, 8, 1, 8, 1, 7], device='cuda:0')\n",
            "Output:  tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 1, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.5412, device='cuda:0')\n",
            "Input:  tensor([5, 2, 8, 1, 3, 8, 5, 6, 5, 8], device='cuda:0')\n",
            "Output:  tensor([5, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.3898, device='cuda:0')\n",
            "Input:  tensor([4, 4, 2, 6, 2, 7, 6, 5, 3, 9], device='cuda:0')\n",
            "Output:  tensor([3, 3, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 5, 3, 9, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.2740, device='cuda:0')\n",
            "Input:  tensor([4, 3, 1, 7, 7, 2, 9, 9, 6, 6], device='cuda:0')\n",
            "Output:  tensor([9, 9, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 9, 6, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.3811, device='cuda:0')\n",
            "Input:  tensor([2, 5, 9, 9, 8, 5, 5, 8, 8, 5], device='cuda:0')\n",
            "Output:  tensor([5, 5, 5, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 5, 5, 8, 8, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.1473, device='cuda:0')\n",
            "Epoch: 02 | Time: 0m 5s\n",
            "\tTrain Loss: 1.047 | Train PPL:   2.850\n",
            "\t Val. Loss: 0.740 |  Val. PPL:   2.097\n",
            "Input:  tensor([0, 5, 1, 5, 8, 2, 3, 9, 7, 7], device='cuda:0')\n",
            "Output:  tensor([5, 8, 8, 8, 7, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 5, 8, 2, 3, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.0181, device='cuda:0')\n",
            "Input:  tensor([2, 4, 2, 2, 4, 7, 4, 6, 9, 7], device='cuda:0')\n",
            "Output:  tensor([4, 4, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 7, 4, 6, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.1227, device='cuda:0')\n",
            "Input:  tensor([2, 6, 4, 7, 2, 2, 6, 8, 9, 3], device='cuda:0')\n",
            "Output:  tensor([2, 2, 2, 8, 8, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 2, 6, 8, 9, 3, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.9699, device='cuda:0')\n",
            "Input:  tensor([3, 2, 2, 2, 6, 9, 5, 4, 2, 5], device='cuda:0')\n",
            "Output:  tensor([6, 6, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.3941, device='cuda:0')\n",
            "Input:  tensor([0, 4, 2, 2, 8, 3, 1, 7, 4, 7], device='cuda:0')\n",
            "Output:  tensor([2, 2, 2, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 2, 8, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.6200, device='cuda:0')\n",
            "Input:  tensor([5, 3, 8, 3, 3, 6, 8, 8, 6, 3], device='cuda:0')\n",
            "Output:  tensor([8, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 6, 3, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.3765, device='cuda:0')\n",
            "Input:  tensor([5, 3, 9, 2, 6, 2, 3, 1, 2, 3], device='cuda:0')\n",
            "Output:  tensor([1, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 2, 3, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.5332, device='cuda:0')\n",
            "Input:  tensor([0, 2, 9, 2, 4, 1, 8, 6, 8, 9], device='cuda:0')\n",
            "Output:  tensor([2, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.4727, device='cuda:0')\n",
            "Epoch: 03 | Time: 0m 5s\n",
            "\tTrain Loss: 0.861 | Train PPL:   2.365\n",
            "\t Val. Loss: 0.688 |  Val. PPL:   1.991\n",
            "Input:  tensor([0, 5, 7, 9, 4, 5, 7, 7, 3, 1], device='cuda:0')\n",
            "Output:  tensor([7, 7, 7, 7, 5, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 9, 4, 5, 7, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.8876, device='cuda:0')\n",
            "Input:  tensor([5, 3, 8, 2, 6, 7, 4, 7, 1, 9], device='cuda:0')\n",
            "Output:  tensor([1, 1, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 1, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.2162, device='cuda:0')\n",
            "Input:  tensor([2, 6, 2, 9, 4, 9, 3, 4, 7, 3], device='cuda:0')\n",
            "Output:  tensor([9, 4, 3, 3, 7, 7, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 9, 3, 4, 7, 3, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.0654, device='cuda:0')\n",
            "Input:  tensor([2, 3, 9, 4, 1, 1, 8, 6, 2, 4], device='cuda:0')\n",
            "Output:  tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 1, 8, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.1740, device='cuda:0')\n",
            "Input:  tensor([4, 2, 4, 8, 5, 6, 6, 7, 4, 5], device='cuda:0')\n",
            "Output:  tensor([6, 7, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 7, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0994, device='cuda:0')\n",
            "Input:  tensor([5, 2, 4, 5, 1, 9, 8, 4, 9, 2], device='cuda:0')\n",
            "Output:  tensor([4, 9, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 9, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.1148, device='cuda:0')\n",
            "Input:  tensor([1, 7, 6, 6, 7, 6, 1, 1, 9, 4], device='cuda:0')\n",
            "Output:  tensor([6, 6, 6, 1, 1, 1, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 7, 6, 1, 1, 9, 4, 0], device='cuda:0')\n",
            "Loss:  tensor(0.9026, device='cuda:0')\n",
            "Input:  tensor([4, 4, 4, 6, 6, 6, 7, 7, 6, 2], device='cuda:0')\n",
            "Output:  tensor([7, 7, 6, 2, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 7, 6, 2, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.2483, device='cuda:0')\n",
            "Epoch: 04 | Time: 0m 5s\n",
            "\tTrain Loss: 0.659 | Train PPL:   1.933\n",
            "\t Val. Loss: 0.464 |  Val. PPL:   1.590\n",
            "Input:  tensor([0, 7, 3, 5, 5, 8, 3, 3, 4, 3], device='cuda:0')\n",
            "Output:  tensor([3, 5, 5, 3, 3, 3, 4, 0], device='cuda:0')\n",
            "Target:  tensor([3, 5, 5, 8, 3, 3, 4, 0], device='cuda:0')\n",
            "Loss:  tensor(0.6261, device='cuda:0')\n",
            "Input:  tensor([5, 3, 6, 8, 5, 8, 5, 1, 1, 5], device='cuda:0')\n",
            "Output:  tensor([1, 1, 5, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 1, 5, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0098, device='cuda:0')\n",
            "Input:  tensor([3, 5, 1, 3, 4, 9, 5, 4, 7, 6], device='cuda:0')\n",
            "Output:  tensor([9, 5, 4, 7, 6, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 5, 4, 7, 6, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.3219, device='cuda:0')\n",
            "Input:  tensor([2, 6, 5, 7, 5, 7, 9, 9, 7, 1], device='cuda:0')\n",
            "Output:  tensor([5, 7, 9, 9, 1, 1, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 7, 9, 9, 7, 1, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.4804, device='cuda:0')\n",
            "Input:  tensor([1, 4, 9, 1, 3, 5, 3, 1, 5, 3], device='cuda:0')\n",
            "Output:  tensor([3, 3, 5, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 3, 5, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.3337, device='cuda:0')\n",
            "Input:  tensor([0, 6, 4, 2, 1, 5, 8, 6, 7, 9], device='cuda:0')\n",
            "Output:  tensor([4, 2, 1, 5, 8, 7, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 2, 1, 5, 8, 6, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.6046, device='cuda:0')\n",
            "Input:  tensor([2, 3, 9, 2, 5, 4, 9, 9, 2, 4], device='cuda:0')\n",
            "Output:  tensor([5, 4, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 4, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0697, device='cuda:0')\n",
            "Input:  tensor([4, 2, 5, 6, 5, 5, 5, 5, 8, 9], device='cuda:0')\n",
            "Output:  tensor([5, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0247, device='cuda:0')\n",
            "Epoch: 05 | Time: 0m 5s\n",
            "\tTrain Loss: 0.460 | Train PPL:   1.584\n",
            "\t Val. Loss: 0.309 |  Val. PPL:   1.362\n",
            "Input:  tensor([4, 4, 5, 7, 9, 6, 2, 3, 1, 9], device='cuda:0')\n",
            "Output:  tensor([2, 3, 1, 9, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 3, 1, 9, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0209, device='cuda:0')\n",
            "Input:  tensor([2, 3, 7, 9, 9, 2, 4, 7, 3, 5], device='cuda:0')\n",
            "Output:  tensor([9, 2, 4, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 2, 4, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0027, device='cuda:0')\n",
            "Input:  tensor([3, 2, 9, 8, 5, 5, 3, 7, 7, 7], device='cuda:0')\n",
            "Output:  tensor([5, 3, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 3, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0009, device='cuda:0')\n",
            "Input:  tensor([3, 3, 7, 4, 7, 5, 5, 3, 1, 3], device='cuda:0')\n",
            "Output:  tensor([5, 5, 3, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 5, 3, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0033, device='cuda:0')\n",
            "Input:  tensor([2, 3, 4, 9, 8, 3, 3, 8, 6, 7], device='cuda:0')\n",
            "Output:  tensor([8, 3, 3, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 3, 3, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0021, device='cuda:0')\n",
            "Input:  tensor([1, 2, 1, 3, 8, 6, 3, 4, 3, 8], device='cuda:0')\n",
            "Output:  tensor([3, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0061, device='cuda:0')\n",
            "Input:  tensor([0, 2, 9, 4, 6, 3, 4, 2, 8, 5], device='cuda:0')\n",
            "Output:  tensor([9, 4, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 4, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0088, device='cuda:0')\n",
            "Input:  tensor([5, 2, 3, 9, 8, 3, 1, 4, 1, 6], device='cuda:0')\n",
            "Output:  tensor([4, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0012, device='cuda:0')\n",
            "Epoch: 06 | Time: 0m 5s\n",
            "\tTrain Loss: 0.268 | Train PPL:   1.307\n",
            "\t Val. Loss: 0.006 |  Val. PPL:   1.006\n",
            "Input:  tensor([0, 6, 7, 3, 7, 2, 4, 9, 6, 7], device='cuda:0')\n",
            "Output:  tensor([7, 3, 7, 2, 4, 9, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 3, 7, 2, 4, 9, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.2351, device='cuda:0')\n",
            "Input:  tensor([1, 3, 6, 5, 8, 9, 6, 4, 2, 7], device='cuda:0')\n",
            "Output:  tensor([5, 8, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 8, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0010, device='cuda:0')\n",
            "Input:  tensor([5, 2, 5, 6, 1, 7, 4, 3, 5, 8], device='cuda:0')\n",
            "Output:  tensor([3, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0009, device='cuda:0')\n",
            "Input:  tensor([4, 4, 1, 6, 7, 4, 2, 8, 8, 7], device='cuda:0')\n",
            "Output:  tensor([2, 8, 8, 7, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 8, 8, 7, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0094, device='cuda:0')\n",
            "Input:  tensor([3, 4, 8, 2, 8, 1, 5, 7, 8, 3], device='cuda:0')\n",
            "Output:  tensor([1, 5, 7, 8, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 5, 7, 8, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0062, device='cuda:0')\n",
            "Input:  tensor([3, 4, 8, 8, 2, 5, 7, 2, 3, 1], device='cuda:0')\n",
            "Output:  tensor([5, 7, 2, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 7, 2, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0056, device='cuda:0')\n",
            "Input:  tensor([1, 7, 3, 1, 5, 5, 6, 7, 5, 4], device='cuda:0')\n",
            "Output:  tensor([1, 5, 5, 5, 7, 5, 4, 0], device='cuda:0')\n",
            "Target:  tensor([1, 5, 5, 6, 7, 5, 4, 0], device='cuda:0')\n",
            "Loss:  tensor(0.3077, device='cuda:0')\n",
            "Input:  tensor([3, 4, 1, 3, 4, 5, 5, 1, 5, 3], device='cuda:0')\n",
            "Output:  tensor([5, 5, 1, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 5, 1, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0074, device='cuda:0')\n",
            "Epoch: 07 | Time: 0m 5s\n",
            "\tTrain Loss: 0.173 | Train PPL:   1.189\n",
            "\t Val. Loss: 0.072 |  Val. PPL:   1.074\n",
            "Input:  tensor([4, 3, 8, 7, 1, 1, 4, 3, 1, 9], device='cuda:0')\n",
            "Output:  tensor([4, 3, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 3, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0022, device='cuda:0')\n",
            "Input:  tensor([5, 2, 2, 5, 8, 1, 1, 8, 5, 9], device='cuda:0')\n",
            "Output:  tensor([8, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([3, 5, 6, 2, 1, 2, 9, 2, 7, 9], device='cuda:0')\n",
            "Output:  tensor([2, 9, 2, 7, 9, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 9, 2, 7, 9, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0563, device='cuda:0')\n",
            "Input:  tensor([2, 4, 5, 6, 3, 3, 6, 5, 7, 1], device='cuda:0')\n",
            "Output:  tensor([3, 3, 6, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 3, 6, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0017, device='cuda:0')\n",
            "Input:  tensor([1, 4, 4, 1, 2, 6, 8, 6, 5, 7], device='cuda:0')\n",
            "Output:  tensor([1, 2, 6, 8, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 2, 6, 8, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0023, device='cuda:0')\n",
            "Input:  tensor([4, 3, 7, 4, 5, 4, 6, 5, 8, 2], device='cuda:0')\n",
            "Output:  tensor([6, 5, 8, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 5, 8, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0004, device='cuda:0')\n",
            "Input:  tensor([3, 4, 4, 5, 9, 5, 2, 1, 6, 6], device='cuda:0')\n",
            "Output:  tensor([5, 2, 1, 6, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 2, 1, 6, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0067, device='cuda:0')\n",
            "Input:  tensor([1, 2, 5, 1, 1, 7, 9, 8, 1, 9], device='cuda:0')\n",
            "Output:  tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0006, device='cuda:0')\n",
            "Epoch: 08 | Time: 0m 5s\n",
            "\tTrain Loss: 0.121 | Train PPL:   1.128\n",
            "\t Val. Loss: 0.009 |  Val. PPL:   1.009\n",
            "Input:  tensor([4, 3, 3, 9, 4, 9, 3, 8, 9, 3], device='cuda:0')\n",
            "Output:  tensor([3, 8, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 8, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0008, device='cuda:0')\n",
            "Input:  tensor([4, 2, 5, 5, 4, 3, 8, 3, 5, 1], device='cuda:0')\n",
            "Output:  tensor([8, 3, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 3, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([4, 3, 6, 9, 6, 5, 2, 6, 7, 5], device='cuda:0')\n",
            "Output:  tensor([2, 6, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 6, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([2, 6, 6, 3, 6, 1, 6, 5, 3, 8], device='cuda:0')\n",
            "Output:  tensor([6, 1, 5, 5, 3, 8, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 1, 6, 5, 3, 8, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.1811, device='cuda:0')\n",
            "Input:  tensor([4, 3, 5, 2, 7, 5, 5, 4, 6, 6], device='cuda:0')\n",
            "Output:  tensor([5, 4, 6, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 4, 6, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([1, 5, 5, 2, 6, 5, 7, 5, 8, 7], device='cuda:0')\n",
            "Output:  tensor([2, 6, 5, 7, 5, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 6, 5, 7, 5, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0107, device='cuda:0')\n",
            "Input:  tensor([0, 6, 3, 1, 1, 5, 3, 7, 7, 8], device='cuda:0')\n",
            "Output:  tensor([3, 1, 1, 5, 3, 7, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 1, 1, 5, 3, 7, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0530, device='cuda:0')\n",
            "Input:  tensor([5, 3, 4, 2, 3, 3, 1, 8, 5, 7], device='cuda:0')\n",
            "Output:  tensor([8, 5, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 5, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Epoch: 09 | Time: 0m 5s\n",
            "\tTrain Loss: 0.090 | Train PPL:   1.094\n",
            "\t Val. Loss: 0.031 |  Val. PPL:   1.031\n",
            "Input:  tensor([3, 5, 3, 6, 6, 6, 5, 2, 8, 2], device='cuda:0')\n",
            "Output:  tensor([6, 5, 2, 8, 2, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 5, 2, 8, 2, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0014, device='cuda:0')\n",
            "Input:  tensor([3, 4, 7, 9, 7, 7, 3, 8, 6, 7], device='cuda:0')\n",
            "Output:  tensor([7, 3, 8, 6, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 3, 8, 6, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([5, 2, 1, 9, 1, 3, 7, 8, 8, 2], device='cuda:0')\n",
            "Output:  tensor([8, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0004, device='cuda:0')\n",
            "Input:  tensor([5, 3, 3, 2, 5, 3, 9, 5, 1, 5], device='cuda:0')\n",
            "Output:  tensor([5, 1, 5, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 1, 5, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0006, device='cuda:0')\n",
            "Input:  tensor([5, 3, 7, 6, 9, 2, 2, 3, 8, 2], device='cuda:0')\n",
            "Output:  tensor([3, 8, 2, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 8, 2, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0003, device='cuda:0')\n",
            "Input:  tensor([2, 6, 8, 4, 1, 7, 5, 7, 4, 2], device='cuda:0')\n",
            "Output:  tensor([1, 7, 5, 7, 4, 2, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 7, 5, 7, 4, 2, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0471, device='cuda:0')\n",
            "Input:  tensor([1, 3, 7, 4, 2, 9, 1, 6, 1, 1], device='cuda:0')\n",
            "Output:  tensor([4, 2, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 2, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([2, 6, 8, 6, 9, 8, 1, 3, 7, 4], device='cuda:0')\n",
            "Output:  tensor([9, 8, 1, 3, 7, 4, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 8, 1, 3, 7, 4, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0662, device='cuda:0')\n",
            "Epoch: 10 | Time: 0m 5s\n",
            "\tTrain Loss: 0.075 | Train PPL:   1.078\n",
            "\t Val. Loss: 0.015 |  Val. PPL:   1.015\n",
            "Input:  tensor([4, 2, 6, 6, 4, 3, 4, 9, 2, 4], device='cuda:0')\n",
            "Output:  tensor([4, 9, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 9, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(9.0635e-05, device='cuda:0')\n",
            "Input:  tensor([2, 3, 5, 8, 8, 1, 7, 4, 8, 4], device='cuda:0')\n",
            "Output:  tensor([8, 1, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 1, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0004, device='cuda:0')\n",
            "Input:  tensor([0, 2, 1, 6, 3, 8, 3, 6, 6, 2], device='cuda:0')\n",
            "Output:  tensor([1, 6, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 6, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0004, device='cuda:0')\n",
            "Input:  tensor([4, 4, 6, 1, 1, 3, 7, 2, 2, 3], device='cuda:0')\n",
            "Output:  tensor([7, 2, 2, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 2, 2, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([3, 2, 6, 9, 1, 9, 4, 2, 4, 5], device='cuda:0')\n",
            "Output:  tensor([9, 4, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 4, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0001, device='cuda:0')\n",
            "Input:  tensor([3, 5, 7, 4, 1, 2, 9, 8, 9, 8], device='cuda:0')\n",
            "Output:  tensor([2, 9, 8, 9, 8, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 9, 8, 9, 8, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0958, device='cuda:0')\n",
            "Input:  tensor([0, 2, 8, 2, 1, 2, 3, 8, 4, 2], device='cuda:0')\n",
            "Output:  tensor([8, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([0, 4, 3, 3, 3, 5, 4, 1, 8, 9], device='cuda:0')\n",
            "Output:  tensor([3, 3, 3, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 3, 3, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0005, device='cuda:0')\n",
            "Epoch: 11 | Time: 0m 5s\n",
            "\tTrain Loss: 0.061 | Train PPL:   1.063\n",
            "\t Val. Loss: 0.012 |  Val. PPL:   1.012\n",
            "Input:  tensor([4, 4, 7, 4, 5, 9, 2, 8, 4, 9], device='cuda:0')\n",
            "Output:  tensor([2, 8, 4, 9, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 8, 4, 9, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0010, device='cuda:0')\n",
            "Input:  tensor([1, 5, 6, 5, 8, 3, 8, 3, 1, 8], device='cuda:0')\n",
            "Output:  tensor([5, 8, 3, 8, 3, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 8, 3, 8, 3, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0030, device='cuda:0')\n",
            "Input:  tensor([4, 3, 1, 6, 2, 4, 4, 1, 8, 9], device='cuda:0')\n",
            "Output:  tensor([4, 1, 8, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 1, 8, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(7.6867e-05, device='cuda:0')\n",
            "Input:  tensor([5, 3, 7, 7, 7, 7, 8, 3, 1, 7], device='cuda:0')\n",
            "Output:  tensor([3, 1, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 1, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0001, device='cuda:0')\n",
            "Input:  tensor([0, 7, 8, 5, 9, 9, 8, 7, 3, 3], device='cuda:0')\n",
            "Output:  tensor([8, 5, 9, 9, 8, 7, 3, 0], device='cuda:0')\n",
            "Target:  tensor([8, 5, 9, 9, 8, 7, 3, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0913, device='cuda:0')\n",
            "Input:  tensor([5, 3, 7, 1, 8, 3, 6, 5, 8, 9], device='cuda:0')\n",
            "Output:  tensor([5, 8, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 8, 9, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(6.6228e-05, device='cuda:0')\n",
            "Input:  tensor([4, 3, 2, 7, 8, 4, 2, 3, 4, 7], device='cuda:0')\n",
            "Output:  tensor([2, 3, 4, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 3, 4, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0003, device='cuda:0')\n",
            "Input:  tensor([2, 4, 3, 6, 5, 1, 8, 8, 1, 7], device='cuda:0')\n",
            "Output:  tensor([5, 1, 8, 8, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 1, 8, 8, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0032, device='cuda:0')\n",
            "Epoch: 12 | Time: 0m 5s\n",
            "\tTrain Loss: 0.044 | Train PPL:   1.045\n",
            "\t Val. Loss: 0.012 |  Val. PPL:   1.012\n",
            "Input:  tensor([3, 4, 7, 6, 3, 7, 7, 5, 1, 6], device='cuda:0')\n",
            "Output:  tensor([7, 7, 5, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 7, 5, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(8.9995e-05, device='cuda:0')\n",
            "Input:  tensor([3, 5, 2, 8, 3, 4, 9, 5, 8, 8], device='cuda:0')\n",
            "Output:  tensor([4, 9, 5, 8, 8, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 9, 5, 8, 8, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0131, device='cuda:0')\n",
            "Input:  tensor([1, 6, 2, 2, 5, 3, 1, 4, 6, 1], device='cuda:0')\n",
            "Output:  tensor([2, 5, 3, 1, 4, 6, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 5, 3, 1, 4, 6, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0043, device='cuda:0')\n",
            "Input:  tensor([5, 3, 7, 6, 5, 5, 2, 7, 3, 7], device='cuda:0')\n",
            "Output:  tensor([7, 3, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 3, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(6.9090e-05, device='cuda:0')\n",
            "Input:  tensor([4, 2, 4, 2, 4, 3, 9, 4, 2, 3], device='cuda:0')\n",
            "Output:  tensor([9, 4, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 4, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(3.9933e-05, device='cuda:0')\n",
            "Input:  tensor([4, 4, 1, 2, 5, 6, 4, 7, 4, 1], device='cuda:0')\n",
            "Output:  tensor([4, 7, 4, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 7, 4, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0003, device='cuda:0')\n",
            "Input:  tensor([0, 2, 3, 8, 8, 6, 9, 2, 8, 2], device='cuda:0')\n",
            "Output:  tensor([3, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(8.2245e-05, device='cuda:0')\n",
            "Input:  tensor([1, 2, 5, 7, 7, 7, 5, 5, 1, 2], device='cuda:0')\n",
            "Output:  tensor([7, 7, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 7, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0001, device='cuda:0')\n",
            "Epoch: 13 | Time: 0m 5s\n",
            "\tTrain Loss: 0.041 | Train PPL:   1.042\n",
            "\t Val. Loss: 0.002 |  Val. PPL:   1.002\n",
            "Input:  tensor([1, 2, 3, 4, 1, 7, 1, 2, 4, 4], device='cuda:0')\n",
            "Output:  tensor([4, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(6.1223e-05, device='cuda:0')\n",
            "Input:  tensor([1, 5, 8, 3, 3, 2, 9, 3, 3, 7], device='cuda:0')\n",
            "Output:  tensor([3, 3, 2, 9, 3, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 3, 2, 9, 3, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0004, device='cuda:0')\n",
            "Input:  tensor([1, 2, 7, 4, 2, 6, 6, 6, 1, 7], device='cuda:0')\n",
            "Output:  tensor([4, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.9505e-05, device='cuda:0')\n",
            "Input:  tensor([4, 4, 5, 2, 7, 7, 4, 3, 5, 2], device='cuda:0')\n",
            "Output:  tensor([4, 3, 5, 2, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 3, 5, 2, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(7.8165e-05, device='cuda:0')\n",
            "Input:  tensor([1, 3, 8, 6, 7, 6, 4, 8, 2, 1], device='cuda:0')\n",
            "Output:  tensor([6, 7, 6, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 7, 6, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(9.0864e-05, device='cuda:0')\n",
            "Input:  tensor([2, 4, 1, 5, 9, 6, 6, 6, 9, 6], device='cuda:0')\n",
            "Output:  tensor([9, 6, 6, 6, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 6, 6, 6, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0003, device='cuda:0')\n",
            "Input:  tensor([5, 3, 9, 5, 6, 3, 2, 6, 1, 4], device='cuda:0')\n",
            "Output:  tensor([6, 1, 4, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 1, 4, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(6.1088e-05, device='cuda:0')\n",
            "Input:  tensor([4, 2, 9, 9, 2, 8, 6, 5, 9, 1], device='cuda:0')\n",
            "Output:  tensor([6, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 5, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(4.4298e-05, device='cuda:0')\n",
            "Epoch: 14 | Time: 0m 5s\n",
            "\tTrain Loss: 0.047 | Train PPL:   1.048\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "Input:  tensor([1, 4, 3, 2, 3, 1, 3, 7, 6, 7], device='cuda:0')\n",
            "Output:  tensor([2, 3, 1, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 3, 1, 3, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0003, device='cuda:0')\n",
            "Input:  tensor([4, 2, 4, 4, 5, 7, 7, 6, 3, 3], device='cuda:0')\n",
            "Output:  tensor([7, 6, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([7, 6, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(2.2441e-05, device='cuda:0')\n",
            "Input:  tensor([3, 5, 1, 6, 2, 6, 9, 7, 7, 2], device='cuda:0')\n",
            "Output:  tensor([6, 9, 7, 7, 2, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 9, 7, 7, 2, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0012, device='cuda:0')\n",
            "Input:  tensor([3, 2, 5, 6, 5, 1, 9, 2, 6, 7], device='cuda:0')\n",
            "Output:  tensor([1, 9, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 9, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(2.7477e-05, device='cuda:0')\n",
            "Input:  tensor([5, 3, 8, 3, 5, 7, 1, 4, 8, 5], device='cuda:0')\n",
            "Output:  tensor([4, 8, 5, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 8, 5, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(9.8511e-05, device='cuda:0')\n",
            "Input:  tensor([5, 2, 4, 2, 1, 4, 2, 5, 3, 8], device='cuda:0')\n",
            "Output:  tensor([5, 3, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 3, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(7.0619e-05, device='cuda:0')\n",
            "Input:  tensor([4, 4, 9, 2, 9, 5, 9, 7, 1, 5], device='cuda:0')\n",
            "Output:  tensor([9, 7, 1, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 7, 1, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([3, 2, 6, 6, 2, 9, 7, 2, 3, 1], device='cuda:0')\n",
            "Output:  tensor([9, 7, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 7, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(3.1723e-05, device='cuda:0')\n",
            "Epoch: 15 | Time: 0m 5s\n",
            "\tTrain Loss: 0.038 | Train PPL:   1.039\n",
            "\t Val. Loss: 0.000 |  Val. PPL:   1.000\n",
            "Input:  tensor([3, 4, 7, 8, 9, 4, 7, 1, 8, 4], device='cuda:0')\n",
            "Output:  tensor([4, 7, 1, 8, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([4, 7, 1, 8, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([3, 4, 3, 9, 7, 5, 3, 1, 1, 7], device='cuda:0')\n",
            "Output:  tensor([5, 3, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 3, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0012, device='cuda:0')\n",
            "Input:  tensor([0, 3, 3, 6, 7, 3, 1, 3, 8, 8], device='cuda:0')\n",
            "Output:  tensor([3, 6, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 6, 7, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0001, device='cuda:0')\n",
            "Input:  tensor([2, 5, 8, 5, 9, 8, 7, 4, 7, 4], device='cuda:0')\n",
            "Output:  tensor([9, 8, 7, 4, 7, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([9, 8, 7, 4, 7, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0004, device='cuda:0')\n",
            "Input:  tensor([4, 4, 3, 4, 5, 3, 5, 7, 8, 5], device='cuda:0')\n",
            "Output:  tensor([5, 7, 8, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([5, 7, 8, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0001, device='cuda:0')\n",
            "Input:  tensor([3, 5, 7, 9, 9, 1, 6, 7, 8, 1], device='cuda:0')\n",
            "Output:  tensor([1, 6, 7, 8, 1, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 6, 7, 8, 1, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0005, device='cuda:0')\n",
            "Input:  tensor([5, 2, 3, 4, 2, 4, 1, 3, 2, 4], device='cuda:0')\n",
            "Output:  tensor([3, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([3, 2, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0002, device='cuda:0')\n",
            "Input:  tensor([1, 6, 4, 1, 4, 8, 4, 5, 4, 2], device='cuda:0')\n",
            "Output:  tensor([1, 4, 8, 4, 5, 4, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 4, 8, 4, 5, 4, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0034, device='cuda:0')\n",
            "Epoch: 16 | Time: 0m 5s\n",
            "\tTrain Loss: 0.035 | Train PPL:   1.036\n",
            "\t Val. Loss: 0.001 |  Val. PPL:   1.001\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 16\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, d_train, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, d_valid, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'subseq-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2bcd4135",
      "metadata": {
        "id": "2bcd4135",
        "outputId": "e4fc2959-d9a0-42af-8822-fb27885bbc07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  tensor([2, 6, 2, 3, 8, 4, 8, 8, 9, 1], device='cuda:0')\n",
            "Output:  tensor([8, 4, 8, 8, 9, 1, 0, 0], device='cuda:0')\n",
            "Target:  tensor([8, 4, 8, 8, 9, 1, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0021, device='cuda:0')\n",
            "Input:  tensor([5, 2, 5, 9, 3, 6, 4, 1, 8, 8], device='cuda:0')\n",
            "Output:  tensor([1, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([1, 8, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(5.1764e-05, device='cuda:0')\n",
            "Input:  tensor([2, 4, 9, 4, 6, 9, 4, 5, 2, 6], device='cuda:0')\n",
            "Output:  tensor([6, 9, 4, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([6, 9, 4, 5, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(6.8823e-05, device='cuda:0')\n",
            "Input:  tensor([0, 3, 2, 5, 1, 6, 8, 5, 4, 6], device='cuda:0')\n",
            "Output:  tensor([2, 5, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Target:  tensor([2, 5, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(0.0001, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0005933678330620751"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "examples = DataLoader(SyntheticDataset(4), batch_size=1)\n",
        "evaluate(model, examples, criterion)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Silly Seq2Seq Shenanigans.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}